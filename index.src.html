<h1>HSTS Priming</h1>
<pre class="metadata">
Status: DREAM
ED: https://w3c.github.io/webappsec-hsts-priming/
Shortname: hsts-priming
Level: 1
Editor: Richard Barnes, Mozilla
Editor: Mike West 56384, Google Inc., mkwst@google.com
Abstract:
  This document proposes modifications to Strict Transport Security's behavior
  in order to mitigate the risk that mixed content blocking will prevent
  migrations from HTTP to HTTPS.
Indent: 2
Markup Shorthands: markdown on
Boilerplate: omit conformance, omit feedback-header
</pre>
<pre class="anchors">
spec: FETCH; urlPrefix: https://fetch.spec.whatwg.org
  type: dfn
    text: request; url: concept-request
    text: HTTP-network fetch
    text: HTTP-network-or-cache fetch
    for: request
      text: client; url: concept-request-client
      text: credentials mode; url:concept-request-credentials-mode
      text: current url; url: concept-request-current-url
      text: destination;  url: concept-request-destination
      text: header list; url: concept-request-header-list
      text: initiator; url: concept-request-initiator
      text: method; url:concept-request-method
      text: origin; url:concept-request-origin
      text: redirect mode; url:concept-request-redirect-mode
      text: referrer policy; url:concept-request-referrer-policy
      text: type; url: concept-request-type
      text: url; url: concept-request-url

spec: URL; urlPrefix: https://url.spec.whatwg.org
  type: dfn
    text: url; url: concept-url

spec: MIX; urlPrefix: https://w3c.github.io/webappsec-mixed-content/
  type: dfn
    text: prohibits mixed security contexts; url: categorize-settings-object

spec: RFC6797; urlPrefix: https://tools.ietf.org/html/rfc6797
  type: dfn
    text: concurrent match; url: section-8.2
    text: superdomain match; url: section-8.2
</pre>
<pre class="biblio">
{
  "TRANSITIONAL": {
      "href": "http://webappsec-test.info/~bhill2/DifferentTakeOnOE.html",
      "title": "Why isn't HTTPS everywhere yet?",
      "authors": [ "Brad Hill" ]
  }
}
</pre>
<!--
████ ██    ██ ████████ ████████   ███████
 ██  ███   ██    ██    ██     ██ ██     ██
 ██  ████  ██    ██    ██     ██ ██     ██
 ██  ██ ██ ██    ██    ████████  ██     ██
 ██  ██  ████    ██    ██   ██   ██     ██
 ██  ██   ███    ██    ██    ██  ██     ██
████ ██    ██    ██    ██     ██  ███████
-->
<section>
  <h2 id="intro">Introduction</h2>

  <em>This section is not normative.</em>

  Migrating sites onto HTTPS is difficult. It has been our common understanding
  that these difficulties were wrapped up in server configuration, performance,
  and certificate maintenance. It's recently become clear that the true
  challenges lie elsewhere. In particular, opting into secure transport comes
  with a number of restrictions which ensure that "secure" really means
  something. Mixed Content in particular can block an upgrade entirely. Brad
  Hill has laid out an excellent explanation of the challenges that mixed
  content blocking presents, and pointed out a number of situations in which
  cross-dependencies between insecure Origin A and Origin B might cause real
  deadlock where no one is able to upgrade without breakage. His
  "Why isn't HTTPS everywhere yet?" document [[TRANSITIONAL]] explains the
  situation quite well, and proposes one approach to solving the problem. This
  document proposes another, which is smaller but simpler.

  Today, the mechanism outlined in [[UPGRADE-INSECURE-REQUESTS]] allows a site
  to make assertions on behalf of the resources it loads that they ought to be
  requested over secure transport. If we provide a similar mechanism to those
  resources' owners, then that new mechanism could be used to break deadlocks by
  allowing Origin B to upgrade to HTTPS, and assert that requests from Origin A
  should be upgraded rather than blocked as mixed content. [[RFC6797]]
  introduced the `Strict-Transport-Security` header, which looks like it could
  be that mechanism.

  HSTS, however, is currently checked after mixed content blocking has already
  happened. This is due to the fundamental property that HSTS takes effect only
  after a user's agent has requested a resource from a host that sends the
  header. The effect is therefore determined by the vagaries of a
  particular user's browsing history. If she visits Origin B before Origin A,
  then Origin A's resources could be upgraded without issue. If she visits
  Origin A first, then those resources won't be upgraded, and the site will
  break in some interesting way.

  Origin A's developer, of course, is overwhelmingly likely to have visited
  Origin B, given the dependencies. This means that they are both extremely
  unlikely to experience the failure, and extremely likely to fall into the
  "Works on my machine!" trap when dealing with user's bug reports. Users
  would be sad, developers would be confused, and the world would collapse into
  an unfortunately indeterminate pile of partially broken sites.

  It doesn't have to be this way, however. This document proposes updates to
  [[FETCH]], [[MIXED-CONTENT]], and [[RFC6797]] which introduce the concept of
  an HSTS priming request. This request will attempt to validate an insecure
  resource's host's HSTS policy before blocking it as mixed content, therefore
  allowing any relevant upgrade from HTTP to HTTPS to be made in a deterministic
  way for all users.

  This is not a recommendation-track document, it simply intends to explain the
  notion of HSTS priming, and gather up relevant changes in a single place for
  discussion. The normative changes will happen in the relevant documents.

  <h3 id="examples">Example</h3>

  Origin A contains the following HTML:

  <pre>
    &lt;script src="http://origin-b/widget.js"&gt;&lt;/script&gt;
  </pre>

  Before blocking this insecure request as mixed content, the user agent
  performs an HSTS priming request to the root of the resource's host, as
  follows:

  <pre>
    HEAD / HTTP/1.1
    Host: origin-b
    ...
  </pre>

  Origin B sends back a response which triggers HSTS for the host:

  <pre>
    HTTP/1.1 200 OK
    ...
    Strict-Transport-Security: max-age=10886400; includeSubDomains
  </pre>
    
  The user agent can then safely upgrade the initial request from HTTP to HTTPS,
  rather than blocking it as mixed content.

  <h3 id="goals">Goals</h3>

  HSTS priming has the overarching goal of removing mixed content as a barrier
  to securing the internet. This breaks down into two concrete objectives:

  1.  Convert the `Strict-Transport-Security` assertion from a negative one
      ("This host is only available via secure transport") to a positive one
      ("Any resource on this host addressed by an insecure scheme is available
      via secure transport. Please grab it from there instead.").

  2.  Teach user agents how to verify this new HSTS assertion early enough in a
      request's lifecycle to avoid being blocked as mixed content.
</section>

<section>
  <h2 id="modifications">Proposed Modifications</h2>

  <h3 id="modifications-fetch">Fetch</h3>

  <h4 id="modifications-fetch-main">Main Fetch Modifications</h4>

  1.  After the current step 3 (which deals with `Upgrade-Insecure-Requests`),
      add the following steps:

      4.  If |request|'s <a for="request">client</a> <a>prohibits mixed security
          contexts</a>, and |request|'s <a for="request">current url</a>'s
          <a for="url">scheme</a> is "`http`" or "`ws`", and its
          <a for="url">host</a> does not
          <a lt="matches the HSTS cache">match the HSTS cache</a>, then
          perform an <a>HSTS priming request</a> for |request|.

  2.  Move the current step 6 (which deals with HSTS) before the current step 4
      (which deals with CSP and mixed content).

      Note: This isn't entirely accurate, as we probably want reporting to
      happen before the upgrade (that is, before the current step 3). That's
      a bug in the existing algorithm that I need to take care of.

      Note: Maybe use the newly defined <a>HSTS cache</a> for the upgrade
      instead of deferring to the RFC.

  <h4 id="modifications-fetch-network">HTTP-network Fetch modifications</h4>

  Modify <a>HTTP-network Fetch</a> as follows:

  1.  After the current step 9 (which processes the `Set-Cookie` header),
      execute the following steps:

      10. If |response|'s <a>header list</a> contains one or more headers
          named `Strict-Transport-Security`, then add an entry to the <a>HSTS
          cache</a> with the following properties:

          :   <a for="HSTS cache entry">host</a>
          ::  |response|'s <a for="request">url</a>'s <a for="url">host</a>
          :   <a for="HSTS cache entry">expiration</a>
          ::  
              ISSUE: Parse the header.
          :   <a for="HSTS cache entry">subdomains</a>
          ::
              ISSUE: Parse the header.
          :   <a for="HSTS cache entry">status</a>
          ::  "`upgrade`"

  <h4 id="modifications-fetch-priming">HSTS Priming Requests</h4>

  To perform an <dfn>HSTS Priming Request</dfn> for |request|, run these steps:

  1.  If |request|'s <a for="request">current url</a>'s <a for="url">scheme</a>
      is not "`http`" or "`ws`", abort these steps.

      Note: I'm assuming that Web Sockets are going to be folded into Fetch at
      some point?

  2.  Let |primer| be a new <a>request</a> whose properties are set as follows:

      :   <a for="request">method</a>
      ::  "`HEAD`"
      :   <a for="request">url</a>
      ::  A new <a>URL</a> whose scheme is "`https`", <a for="url">host</a> is
          |request|'s <a for="request">current url</a>'s <a for="url">host</a>,
          and <a for="url">port</a> is |request|'s <a for="request">current
          url</a>'s <a for="url">port</a>
      :   <a for="request">initiator</a>
      ::  |request|'s <a for="request">initiator</a>
      :   <a for="request">type</a>
      ::  |request|'s <a for="request">type</a>
      :   <a for="request">destination</a>
      ::  |request|'s <a for="request">destination</a>
      :   <a for="request">credentials mode</a>
      ::  |request|'s <a for="request">credentials mode</a>
      :   <a for="request">redirect mode</a>
      ::  "`manual`"
      :   <a for="request">client</a>
      :   `null`
      :   <a for="request">referrer policy</a>
      ::  "`no-referrer`"

  3.  <a>Append</a> a header named "`Upgrade-Insecure-Requests`" with a value of
      "`1`" to |primer|'s <a>header list</a>.

  4.  Let |response| be the result of performing an <a>HTTP-network-or-cache
      fetch</a> using |primer|.

  5.  If |response|'s <a>header list</a> does not contain one or more headers
      named `Strict-Transport-Security`, then add an entry to the <a>HSTS
      cache</a> with the following properties:

      :   <a for="HSTS cache entry">host</a>
      ::  |primer|'s <a for="request">url</a>'s <a for="url">host</a>
      :   <a for="HSTS cache entry">expiration</a>
      ::  A reasonable expiration. Perhaps 24 hours? 
      :   <a for="HSTS cache entry">subdomains</a>
      ::  "`exclude`"
      :   <a for="HSTS cache entry">status</a>
      ::  "`do not upgrade`"

  <h4 id="modifications-fetch-hsts-cache">HSTS Cache</h4>

  An <dfn>HSTS cache</dfn> consists of a collection of <dfn>HSTS cache
  entry</dfn> objects, each with the following properties:

  :   <dfn for="HSTS cache entry">host</dfn>
  ::  A <a for="url">host</a>
  :   <dfn for="HSTS cache entry">expiration</dfn>
  ::  A timestamp, after which this entry is no longer valid
  :   <dfn for="HSTS cache entry">subdomains</dfn>
  ::  "`include`" or "`exclude`"
  :   <dfn for="HSTS cache entry">status</dfn>
  ::  "`upgrade`" or "`do not upgrade`"

  <h4 id="modifications-fetch-hsts-cache-matching" algorithm>
    Does |request| match the HSTS cache?
  </h4>
  A <a>request</a> (|request|) <dfn>matches the HSTS cache</dfn> if there exists
  an <a>HSTS cache entry</a> |entry| in the user agent's <a>HSTS cache</a> such
  that:

  1.  The current time is not after |entry|'s
      <a for="HSTS cache entry">expiration</a>

  2.  |entry|'s <a for="HSTS cache entry">host</a> is a <a>concurrent match</a>
      for |request|'s <a for="request">current url</a>'s <a for="url">host</a>
      
      or
      
      |entry|'s <a for="HSTS cache entry">subdomains</a> is "`include`", and
      |entry|'s <a for="HSTS cache entry">host</a> is a <a>superdomain match</a>
      for |request|'s <a for="request">current url</a>'s <a for="url">host</a>

  <h3 id="modifications-mixed-content">Mixed Content</h3>

  1.  Explain the nature of the relationship to HSTS.

  <h3 id="modifications-hsts">RFC 6797</h3>

  1.  Explain the nature of the new assertion that's being made, and its
      implications.

  2.  Integrate the spec with Fetch.

  ISSUE: Lots more specifics everywhere.
</section>

<section>
  <h2 id="open-questions">Open Questions</h2>

  1.  Would it be valuable enough to do this for navigational requests as well?
      That would have the impact of making the initial window for attack
      marginally smaller (e.g. the attacker would have to actively block
      connections over 443, rather than executing an ssl stripping attack), but
      it's not clear that there's much value in the additional complexity.
</section>

<section>
  <h2 id="security-considerations">Security Considerations</h2>

  HSTS priming makes it more likely that developers can upgrade their sites from
  HTTP to HTTPS, as discussed in the introduction.

  It has the nice side-effect of making it possible for CDNs and widget
  providers to increase the security of the web in one fell swoop, which
  increases the value of the `Strict-Transport-Security` header significantly.
</section>
<section>
  <h2 id="privacy-considerations">Privacy Considerations</h2>

  <h3 id="divergent-hosts">Leakage via Divergent Hosts</h3>

  As little sense as it may make, some hosts do serve different content via
  HTTPS than they serve via HTTP (`forbes.com` is the canonical example). HSTS
  priming has the potential of leaking information about insecure resource
  requests to the secure variant of the requests' host. We mitigate this risk
  by stripping out interesting information from the priming request. It does
  not contain referrer information (as we set the referrer policy to `none`), it
  contains no credential information, and it doesn't contain the URL of the
  resource being requested (as we target the root of the secure origin).

  <h3 id="history">History Leakage</h3>

  The HSTS state of a host leaks some information about a user's browsing
  history. Likewise, if the user agent caches failed HSTS priming requests,
  those failures leak information. User agents SHOULD give users the ability
  to clear these caches, and should expire them in a reasonable amount of time.
</section>

<!--
   ███     ██████  ██    ██ ██    ██  ███████  ██      ██ ██       ████████ ████████   ██████   ████████ ██     ██ ████████ ██    ██ ████████  ██████
  ██ ██   ██    ██ ██   ██  ███   ██ ██     ██ ██  ██  ██ ██       ██       ██     ██ ██    ██  ██       ███   ███ ██       ███   ██    ██    ██    ██
 ██   ██  ██       ██  ██   ████  ██ ██     ██ ██  ██  ██ ██       ██       ██     ██ ██        ██       ████ ████ ██       ████  ██    ██    ██
██     ██ ██       █████    ██ ██ ██ ██     ██ ██  ██  ██ ██       ██████   ██     ██ ██   ████ ██████   ██ ███ ██ ██████   ██ ██ ██    ██     ██████
█████████ ██       ██  ██   ██  ████ ██     ██ ██  ██  ██ ██       ██       ██     ██ ██    ██  ██       ██     ██ ██       ██  ████    ██          ██
██     ██ ██    ██ ██   ██  ██   ███ ██     ██ ██  ██  ██ ██       ██       ██     ██ ██    ██  ██       ██     ██ ██       ██   ███    ██    ██    ██
██     ██  ██████  ██    ██ ██    ██  ███████   ███  ███  ████████ ████████ ████████   ██████   ████████ ██     ██ ████████ ██    ██    ██     ██████
-->
<section>
  <h2 id="acknowledgements">Acknowledgements</h2>

  Richard Barnes <a href="https://lists.w3.org/Archives/Public/public-webappsec/2015Aug/0095.html">proposed this treatment</a>
  in a thread that included very helpful comments from Eric Mill, Brad Hill,
  Mark Nottingham, Brian Smith, Tanvi Vyas, Martin Thomson, and Anne van
  Kesteren.
</section>
